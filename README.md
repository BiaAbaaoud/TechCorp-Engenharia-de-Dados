# TechCorp: Engenharia de Dados e Resili√™ncia de Infraestrutura

Este projeto simula um ecossistema de monitoramento de infraestrutura focado em resili√™ncia de dados (DRP) e efici√™ncia de armazenamento. Implementamos um pipeline ETL para migra√ß√£o de logs cr√≠ticos de um banco relacional para um formato colunar otimizado.

### üéØ Objetivo
Reduzir custos de armazenamento e processamento atrav√©s da migra√ß√£o de dados de um banco relacional (SQLite) para o formato Parquet, garantindo uma estrat√©gia de **Disaster Recovery** e visualiza√ß√£o executiva para suporte √† decis√£o r√°pida.

### üõ†Ô∏è O Que Foi Feito
1. **Ingest√£o & Simula√ß√£o:** Gera√ß√£o de logs sint√©ticos contendo lat√™ncia e status HTTP.
2. **Armazenamento:** Persist√™ncia inicial em SQLite.
3. **Otimiza√ß√£o:** Migra√ß√£o para `.parquet` com compress√£o *snappy*.
4. **Resili√™ncia:** Implementa√ß√£o de rotina de restaura√ß√£o autom√°tica (Data Recovery).

### üìÇ Estrutura de Documentos
* `migracao_dados_parquet.py`: Script de gera√ß√£o e convers√£o SQL -> Parquet.
* `auditoria_infra.py`: Analisador de logs e lat√™ncia.
* `restaurar_dados.py`: Mecanismo de Disaster Recovery.
* `dashboard_executivo.py`: Gera o relat√≥rio visual `analise_viva_techcorp.png`.
* `shieldbank_credito.db`: Banco de dados relacional.
* `backup_infra_techcorp.parquet`: Dataset otimizado.

### üß∞ Ferramentas Utilizadas
* **Python 3.x**
* **Pandas** (Manipula√ß√£o de dados)
* **SQLite3** (Banco Relacional)
* **PyArrow** (Motor para Parquet)
* **Matplotlib/Seaborn** (Visualiza√ß√£o)

### üöÄ Como Executar o Projeto
1. **Gera√ß√£o:** `python migracao_dados_parquet.py`
2. **Auditoria:** `python auditoria_infra.py`
3. **Dashboard:** `python dashboard_executivo.py`
4. **Restaura√ß√£o:** `python restaurar_dados.py`

### ‚ùì FAQ - Perguntas Frequentes

**1. Por que migrar de SQLite para Parquet?**
O Parquet utiliza armazenamento colunar e compress√£o Snappy, o que reduz o espa√ßo em disco em mais de 60% e acelera drasticamente consultas para an√°lise de Big Data.

**2. Qual a principal m√©trica de performance monitorada?**
A Lat√™ncia M√©dia (ms). O sistema identifica gargalos em servidores espec√≠ficos (como AWS, Azure ou GCP) para sugerir o rebalanceamento de carga imediato.

**3. Como o projeto lida com erros cr√≠ticos?**
O monitoramento foca nos Status HTTP 4xx (erro do cliente) e 5xx (erro de servidor). O dashboard visual categoriza essas falhas para que a equipe de SRE possa atuar na regi√£o correta.

**4. O projeto √© escal√°vel?**
Sim. A estrutura de scripts e o formato Parquet s√£o os padr√µes utilizados em grandes clusters de dados, permitindo que este mesmo pipeline processe milh√µes de registros com alta efici√™ncia.

**5. Quais bibliotecas s√£o necess√°rias para rodar o projeto?**
Para executar todos os scripts e gerar os gr√°ficos, utilize: `pip install pandas pyarrow matplotlib seaborn`.

**6. Como o Disaster Recovery √© testado?**
Ao executar `python restaurar_dados.py`, o sistema busca o backup imut√°vel em Parquet e reconstr√≥i o banco de dados SQL do zero, simulando a recupera√ß√£o ap√≥s uma perda total da tabela original.

---
**Desenvolvedora:** [BiaAbaaoud](https://github.com/BiaAbaaoud)